{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random,math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,cohen_kappa_score,accuracy_score\n",
    "from sklearn import datasets, svm ,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/black/LBPTOP_npy/old'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'LBPTOP_npy/Drunk'\n",
    "Drunk=[]\n",
    "for filename in os.listdir(directory):\n",
    "    Drunk.append(os.path.join(directory, filename))\n",
    "\n",
    "directory = 'LBPTOP_npy/Sober'\n",
    "Sober=[]\n",
    "for filename in os.listdir(directory):\n",
    "    Sober.append(os.path.join(directory, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drunk_data = []\n",
    "for filename in Drunk:\n",
    "    file = np.load(filename)\n",
    "    Drunk_data.append(file)\n",
    "\n",
    "Drunk_data = np.array(Drunk_data)\n",
    "\n",
    "Sober_data = []\n",
    "for filename in Sober:\n",
    "    file = np.load(filename) \n",
    "    Sober_data.append(file)\n",
    "\n",
    "Sober_data = np.array(Sober_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((Drunk_data , Sober_data))\n",
    "zeros = np.zeros(len(Drunk_data))\n",
    "ones = np.ones(len(Sober_data))\n",
    "y = np.concatenate((zeros, ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X, y))\n",
    "random.shuffle(c)\n",
    "X, y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(X),len(y))\n",
    "fraction = 0.85 #size of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3118 3118 2650\n"
     ]
    }
   ],
   "source": [
    "num_of_Train_exp = math.floor(len(X)*(fraction))\n",
    "print(len(X),len(y),num_of_Train_exp)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650 467 2650 467\n"
     ]
    }
   ],
   "source": [
    "X_train = X[0:num_of_Train_exp]\n",
    "X_test = X[num_of_Train_exp:-1]\n",
    "y_train = y[0:num_of_Train_exp]\n",
    "y_test = y[num_of_Train_exp:-1]\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_data(model=None):\n",
    "    predictions = model.predict(X_test)\n",
    "    correct_classifications = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if predictions[i] == y_test[i]:\n",
    "            correct_classifications += 1\n",
    "    accuracy = 100*correct_classifications/len(y_test) #Accuracy as a percentage\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = svm.SVC(C=1.0, kernel='rbf',gamma=1.0)\n",
    "#clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0085653104925 % accuracy obtained with kernel = rbf\n",
      "Classification report for classifier SVC(C=16, cache_size=800, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=16, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.85      0.86       211\n",
      "        1.0       0.88      0.91      0.89       256\n",
      "\n",
      "avg / total       0.88      0.88      0.88       467\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[179  32]\n",
      " [ 24 232]]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=16, kernel='rbf',gamma=16,cache_size=800)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = evaluate_on_test_data(clf)\n",
    "print(\"{} % accuracy obtained with kernel = rbf\".format(acc))\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"% (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
